<!DOCTYPE html><html lang="en-US"><head><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1"/><title>Write a stream ripper with MediaRecorder</title><link rel="stylesheet" href="/index.css"/><script src="/sw.js"></script></head><body><div class="fonts-loader"><div>0</div><div style="font-style:italic">1</div><div style="font-weight:bold">2</div><div style="font-weight:bold;font-style:italic">3</div></div><header class="main-nav"><nav><ul class="nav-list"><li><h1><a href="/">Blog</a></h1></li><li><a href="/archive">Archive</a></li><li><a href="/about">About</a></li></ul></nav><button class="lamp"><svg viewBox="0 0 100 100"><circle cx="50" cy="50" r="35" fill="none" stroke-width="10"></circle><path d="M 50 70 A 20 20 0 0 1 50 30"></path><path d="M 50 70 A 20 20 0 0 0 50 30"></path></svg></button><script>
document.querySelector('.lamp').addEventListener('click', toggleColorScheme)

const darkModeMediaQuery = matchMedia('(prefers-color-scheme: dark)')
darkModeMediaQuery.addListener(toggleColorScheme)

const documentClasses = document.documentElement.classList
documentClasses.add(getColorScheme())

function getColorScheme() {
   const savedColorScheme = localStorage.getItem('color-scheme')

   if (savedColorScheme) {
      return savedColorScheme === 'dark' ? 'dark' : 'light'
   }

   return darkModeMediaQuery.matches ? 'dark' : 'light'
}

function toggleColorScheme() {
   const colorScheme = getColorScheme()
   documentClasses.remove(colorScheme)

   const nextColorScheme = colorScheme === 'dark' ? 'light' : 'dark'
   documentClasses.add(nextColorScheme)
   localStorage.setItem('color-scheme', nextColorScheme)
}
</script></header><h1 id="write-a-stream-ripper-with-mediarecorder" class="post-heading"><a href="#write-a-stream-ripper-with-mediarecorder">Write a stream ripper with MediaRecorder</a></h1><aside class="contents">Contents<nav><ul><li><a href="#write-a-stream-ripper-with-mediarecorder">Write a stream ripper with MediaRecorder</a><ul><li><a href="#mediastream">
         MediaStream
      </a><ul><li><a href="#media-devices">
         Media Devices
      </a></li><li><a href="#canvas">
         Canvas
      </a></li><li><a href="#media-elements">
         Media Elements
      </a></li></ul></li><li><a href="#using-mediarecorder">
         Using MediaRecorder
      </a></li><li><a href="#customising">
         Customising
      </a><ul><li><a href="#1-media-parameters">
         1. Media parameters
      </a></li><li><a href="#2-capturing-time-slices">
         2. Capturing time slices
      </a></li></ul></li><li><a href="#polyfills">
         Polyfills
      </a></li><li><a href="#rocky-performance">
         Rocky performance
      </a><ul><li><a href="#1-partial-metadata">
         1. Partial Metadata
      </a></li><li><a href="#2-adaptive-streaming">
         2. Adaptive Streaming
      </a></li></ul></li><li><a href="#the-end-3">
         The end
      </a></li></ul></li></ul></nav></aside><script>
const topThreshold = 20

const initialTop = 270 // refer index.css for .contents top offset
const finalTop = 100

let prevTop = 0

window.addEventListener('scroll', contentsMain, {
   passive: true,
})

window.addEventListener('resize', contentsMain, {
   passive: true,
})

setTimeout(contentsMain, 1000)

function contentsMain() {
   if (window.innerWidth >= 1300) {
      moveSidebar()
      highlightCurrentSection()
   } else {
      resetSidebar()
   }
}

function highlightCurrentSection() {
   const $contents = document.querySelector('.contents')

   const $targetLink = Array.from($contents.querySelectorAll('a'))
      .reverse()
      .find((a, i) => {
         const id = a.getAttribute('href').slice(1)
         const h = document.getElementById(id)
         const top = h.getBoundingClientRect().top
         return top < topThreshold
      })

   if (!$targetLink) {
      return
   }

   $contents.querySelectorAll('.current-section').forEach($currentSection => {
      $currentSection.classList.remove('current-section')
   })

   $targetLink.classList.add('current-section')
}

function moveSidebar() {
   const top = Math.max(finalTop, initialTop - window.scrollY)

   if (prevTop === top) {
      return
   }

   prevTop = top

   const $contents = document.querySelector('.contents')
   $contents.style.top = top + 'px'
}

function resetSidebar() {
   const $contents = document.querySelector('.contents')

   $contents.style.top = 0

   $contents.querySelectorAll('.current-section').forEach($currentSection => {
      $currentSection.classList.remove('current-section')
   })
}
</script><article><p>The new <a href="https://developer.mozilla.org/docs/Web/API/MediaRecorder"><code>MediaRecorder</code></a> WebAPI makes media recording super easy.
It allows storing chunks of data from a <a href="https://developer.mozilla.org/docs/Web/API/MediaStream">media stream</a> as blobs, which can later be concatenated and saved as a single file.
As time passes, more sources of media streams are added.
We can capture media from:</p>
<ul>
<li>Media Devices</li>
<li>Canvas</li>
<li>Media Elements:<ul>
<li><code>&lt;video /&gt;</code></li>
<li><code>&lt;audio /&gt;</code></li>
</ul>
</li>
</ul>

      <h2 id="mediastream" class="post-heading">
         <a href="#mediastream">MediaStream</a>
      </h2>
   
      <h3 id="media-devices" class="post-heading">
         <a href="#media-devices">Media Devices</a>
      </h3>
   <p>The key component in using <code>MediaRecorder</code> is having access to a MediaStream.
The early uses of MediaStreams came with the use of <code>getUserMedia()</code> method to gain access to local media devices.</p>

   <figure>
      <pre class="hljs"><code>navigator.mediaDevices.getUserMedia().then(<span class="hljs-function"><span class="hljs-params">stream</span> =&gt;</span> {
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">&#x27;Captured MediaStream:&#x27;</span>, stream)
})</code></pre>
      
   </figure>

      <h3 id="canvas" class="post-heading">
         <a href="#canvas">Canvas</a>
      </h3>
   <p>The <a href="https://developer.mozilla.org/docs/Web/API/HTMLCanvasElement"><code>&lt;canvas /&gt;</code></a> element implements a method
<a href="https://developer.mozilla.org/docs/Web/API/HTMLCanvasElement/captureStream"><code>captureStream()</code></a>
that captures content rendered on the canvas element, each time the content changes.</p>
<p>We can supply an optional argument that controls the number of frames recorded per second (FPS).</p>

   <figure>
      <pre class="hljs"><code><span class="hljs-comment">// frames recorded only on re-renders</span>
<span class="hljs-keyword">const</span> stream = canvas.captureStream()

<span class="hljs-comment">// 30 frames recorded per second</span>
<span class="hljs-keyword">const</span> stream = canvas.captureStream(<span class="hljs-number">30</span>)</code></pre>
      
   </figure>
<p><strong>Note:</strong> To stream returned by <code>canvas.captureStream()</code> is of type <a href="https://developer.mozilla.org/docs/Web/API/CanvasCaptureMediaStream"><code>CanvasCaptureMediaStream</code></a> and not <code>MediaStream</code>.
This difference will be important later.</p>

      <h3 id="media-elements" class="post-heading">
         <a href="#media-elements">Media Elements</a>
      </h3>
   <p>In modern browsers, the <code>HTMLMediaElement</code> interface also adds the method
<a href="https://developer.mozilla.org/docs/Web/API/HTMLMediaElement/captureStream"><code>captureStream()</code></a>
that <em>pipes</em> the media content into a continuous stream.
Since <code>HTMLMediaElement</code> is implemented by both <code>&lt;video /&gt;</code> and <code>&lt;audio /&gt;</code> elements, we can capture media streams from both these elements.</p>
<p>But there&#39;s a difference.
Here, the frames are captured in <em>real time</em>.
If the video being recorded is paused, the frozen frame will be captured repeatedly.</p>
<p><strong>Note:</strong> To use this method in Google Chrome, you need to enable the &quot;Experimental Web Platform features&quot; flag.
You can copy/paste the below for quick access.</p>

   <figure>
      <pre class="hljs"><code>chrome://flags/#enable-experimental-web-platform-features</code></pre>
      
   </figure>

      <h2 id="using-mediarecorder" class="post-heading">
         <a href="#using-mediarecorder">Using MediaRecorder</a>
      </h2>
   <p>Using the <code>MediaRecorder</code> API is super simple.
Here&#39;s a short snippet that highlights all the key parts.</p>

   <figure>
      <pre class="hljs"><code><span class="hljs-comment">// Get a MediaStream object to record</span>
<span class="hljs-comment">// and pass it to MediaRecorder constructor</span>
<span class="hljs-comment">// to create a MediaRecorder instance `recorder`</span>
<span class="hljs-keyword">const</span> stream = mediaElement.captureStream()
<span class="hljs-keyword">const</span> recorder = <span class="hljs-keyword">new</span> MediaRecorder(stream)

<span class="hljs-comment">// When recording starts, the captured frames are emitted</span>
<span class="hljs-comment">// as `dataavailable` events on the `recorder`.</span>
<span class="hljs-comment">// These captured &quot;chunks&quot; can be collected in an array.</span>
<span class="hljs-keyword">const</span> allChunks = []
recorder.ondataavailable = <span class="hljs-function"><span class="hljs-params">e</span> =&gt;</span> {
  allChunks.push(e.data)
}

<span class="hljs-comment">// Start recording</span>
recorder.start()

<span class="hljs-comment">// We can pause capturing media and resume again later</span>
<span class="hljs-comment">// to deal with irregular media playback</span>
<span class="hljs-comment">// (likely due to user interactions or buffering)</span>
recorder.pause()
recorder.resume()

<span class="hljs-comment">// When we&#x27;re done, we can stop recording.</span>
<span class="hljs-comment">// This ensures that no more media chunks are captured,</span>
<span class="hljs-comment">// even if media playback continues.</span>
recorder.stop()

<span class="hljs-comment">// We can now join all the chunks</span>
<span class="hljs-comment">// into a single &quot;blob&quot; ...</span>
<span class="hljs-keyword">const</span> fullBlob = <span class="hljs-keyword">new</span> Blob(allChunks)

<span class="hljs-comment">// ... which we can download using HTML5 `download` attribute on &lt;a /&gt;</span>
<span class="hljs-keyword">const</span> link = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;a&#x27;</span>)
link.style.display = <span class="hljs-string">&#x27;none&#x27;</span>

<span class="hljs-keyword">const</span> downloadUrl = <span class="hljs-built_in">window</span>.URL.createObjectURL(fullBlob)
link.href = downloadUrl
link.download = <span class="hljs-string">&#x27;media.webm&#x27;</span>

<span class="hljs-built_in">document</span>.body.appendChild(link)
link.click()
link.remove()</code></pre>
      
   </figure>

      <h2 id="customising" class="post-heading">
         <a href="#customising">Customising</a>
      </h2>
   
      <h3 id="1-media-parameters" class="post-heading">
         <a href="#1-media-parameters">1. Media parameters</a>
      </h3>
   <p>The constructor takes an optional argument that can have the following options:</p>
<ul>
<li><code>mimeType</code>: The mime type to use for the recording.</li>
<li><code>audioBitsPerSecond</code>: The bitrate for the audio component of the media.</li>
<li><code>videoBitsPerSecond</code>: The bitrate for the video component of the media.</li>
<li><code>bitsPerSecond</code>: The bitrate for both, the audio and the video components of the media.</li>
</ul>
<p>If <code>bitsPerSecond</code> is provided with one of <code>audioBitsPerSecond</code> or <code>videoBitsPerSecond</code>, it will be applied to the missing one.</p>
<p>Out of them all, <code>mimeType</code> is the most important one.
It controls the codecs used for encoding audio and video components.</p>

   <figure>
      <pre class="hljs"><code><span class="hljs-keyword">const</span> codec = <span class="hljs-string">&#x27;video/webm&#x27;</span>;

<span class="hljs-keyword">const</span> recorder = <span class="hljs-keyword">new</span> MediaRecorder(stream, {
  <span class="hljs-attr">mimeType</span>: codec,
  <span class="hljs-attr">audioBitsPerSecond</span>: <span class="hljs-number">1000000</span> <span class="hljs-comment">// 1 Mbps</span>
  <span class="hljs-attr">bitsPerSecond</span>: <span class="hljs-number">1000000</span>      <span class="hljs-comment">// 2 Mbps</span>
  <span class="hljs-comment">// videoBitsPerSecond will also be 2 Mbps</span>
});</code></pre>
      
   </figure>
<p>To check if a codec is supported, use <a href="https://developer.mozilla.org/docs/Web/API/MediaRecorder/isTypeSupported"><code>MediaRecorder.isTypeSupported()</code></a>.</p>

   <figure>
      <pre class="hljs"><code>MediaRecorder.isTypeSupported(<span class="hljs-string">&#x27;video/webm&#x27;</span>) <span class="hljs-comment">// true</span>
MediaRecorder.isTypeSupported(<span class="hljs-string">&#x27;video/mp4&#x27;</span>) <span class="hljs-comment">// false</span></code></pre>
      
   </figure>
<p>At the time of writing, the supported codecs are:</p>

   <figure>
      <pre class="hljs"><code><span class="hljs-comment"># audio codecs</span>
audio/webm
audio/webm;codecs=opus

<span class="hljs-comment"># video codecs</span>
video/webm
video/webm;codecs=avc1

video/webm;codecs=h264
video/webm;codecs=h264,opus

video/webm;codecs=vp8
video/webm;codecs=vp8,opus

video/webm;codecs=vp9
video/webm;codecs=vp9,opus

video/webm;codecs=h264,vp9,opus
video/webm;codecs=vp8,vp9,opus

video/x-matroska
video/x-matroska;codecs=avc1</code></pre>
      
   </figure>

      <h3 id="2-capturing-time-slices" class="post-heading">
         <a href="#2-capturing-time-slices">2. Capturing time slices</a>
      </h3>
   <p>We can pass an optional argument to <code>MediaRecorder.start()</code>.
This is the <code>timeslice</code>.
It is the duration (in milliseconds) of the segment of captured media, emitted in each event.</p>
<p>If not specified, all media captured will be returned in a single Blob.</p>

      <h2 id="polyfills" class="post-heading">
         <a href="#polyfills">Polyfills</a>
      </h2>
   <p>At the time of writing, the whole <code>MediaRecorder</code> API is <em>bleeding edge</em> and support for <a href="https://developer.mozilla.org/docs/Web/API/HTMLMediaElement/captureStream"><code>HTMLMediaElement.captureStream()</code></a> is rare.
But there&#39;s a way to make it work.</p>
<p>For capturing audio stream, we can use the <a href="https://developer.mozilla.org/docs/Web/API/Web_Audio_API">Web Audio API</a>.
There are 3 steps:</p>
<ol>
<li>Create a source node from the media element.</li>
<li>Create a stream destination node.</li>
<li>Connect the source node to the stream destination node.</li>
</ol>
<p>For capturing video stream, we can render a <code>&lt;video /&gt;</code> element onto a <code>&lt;canvas /&gt;</code> element and capture frames from it.</p>

   <figure>
      <pre class="hljs"><code><span class="hljs-comment">// audio polyfill</span>

<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">polyfillAudio</span>(<span class="hljs-params">mediaElement</span>) </span>{
  <span class="hljs-keyword">const</span> audioCtx = <span class="hljs-keyword">new</span> AudioContext()

  <span class="hljs-comment">// create a source node and a stream destination node</span>
  <span class="hljs-keyword">const</span> source = audioCtx.createMediaElementSource(mediaElement)
  <span class="hljs-keyword">const</span> destination = audioCtx.createMediaStreamDestination()

  <span class="hljs-comment">// Connect the source node to the stream destination node</span>
  <span class="hljs-comment">// to push audio content into the stream</span>
  source.connect(destination)

  <span class="hljs-comment">// Connect the source node to the audio context&#x27;s destination node</span>
  <span class="hljs-comment">// so the playback can still deliver audio</span>
  source.connect(audioCtx.destination)

  <span class="hljs-keyword">const</span> audioStream = destination.stream

  <span class="hljs-keyword">return</span> audioStream
}

<span class="hljs-comment">// video polyfill</span>

<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">polyfillVideo</span>(<span class="hljs-params">mediaElement</span>) </span>{
  <span class="hljs-comment">// Create a canvas element</span>
  <span class="hljs-keyword">const</span> canvas = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&#x27;canvas&#x27;</span>)

  <span class="hljs-comment">// Start rendering video frames onto the canvas</span>
  renderVideoFrame(canvas, videoElement)

  <span class="hljs-keyword">const</span> videoStream = canvas.captureStream(<span class="hljs-number">60</span>)

  <span class="hljs-keyword">return</span> videoStream
}

<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">renderVideoFrame</span>(<span class="hljs-params">canvas, videoElement</span>) </span>{
  <span class="hljs-keyword">const</span> ctx = canvas.getContext(<span class="hljs-string">&#x27;2d&#x27;</span>)

  ctx.drawImage(videoElement, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, canvas.width, canvas.height)

  <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function">() =&gt;</span> renderVideoFrame(canvas, videoElement))
}</code></pre>
      
   </figure>
<p>Now we need to do combine the 2 streams and <em>voila!</em></p>

   <figure>
      <pre class="hljs"><code><span class="hljs-keyword">const</span> stream = <span class="hljs-keyword">new</span> MediaStream([
  ...audioStream.getTracks(),
  ...videoStream.getTracks(),
])</code></pre>
      
   </figure>

      <h2 id="rocky-performance" class="post-heading">
         <a href="#rocky-performance">Rocky performance</a>
      </h2>
   <p>There are a few bumps in using <code>MediaRecorder</code>.</p>

      <h3 id="1-partial-metadata" class="post-heading">
         <a href="#1-partial-metadata">1. Partial Metadata</a>
      </h3>
   <p>One serious problem is that the saved recordings have no duration attribute.
To record media, <code>MediaRecorder</code> uses the <a href="https://en.wikipedia.org/wiki/Matroska">Matroska</a> container format.
The <a href="https://www.matroska.org/technical/specs/index.html">Matroska format</a> doesn&#39;t treat duration as a mandatory element.</p>
<p>As a result, it is not embedded in the file&#39;s header.</p>
<p>Also, adding it isn&#39;t an easy procedure, nor is it simple - it&#39;s doable, but &quot;takes more than a weekend&quot; kind of doable.</p>

      <h3 id="2-adaptive-streaming" class="post-heading">
         <a href="#2-adaptive-streaming">2. Adaptive Streaming</a>
      </h3>
   <p>When capturing videos served using <a href="https://developer.mozilla.org/docs/Web/HTML/DASH_Adaptive_Streaming_for_HTML_5_Video">DASH Adaptive Streaming</a>, changing the resolution causes frame corruption.
I haven&#39;t yet figured out a way to sole this problem, but using the <code>&lt;canvas /&gt;</code> polyfill seems to work just fine.</p>
<p>Here&#39;s a demo video highlighting the 2 problems.</p>

   <figure>
      <video  src="media.webm" controls=""></video>
      
   </figure>

      <h2 id="the-end-3" class="post-heading">
         <a href="#the-end-3">The end</a>
      </h2>
   <p>In the future, as browser support for grows, people and organisations alike will start rolling out extensions, plugins and softwares allowing client-side media capturing.
It can be used in an <a href="https://electron.atom.io/apps">electron apps</a> like camera, video calling, media player.
But for today, it is more or less an niche experimental toy.</p>
<p>At this point, it&#39;d be good to have some <a href="%7B%7Bsite.baseurl%7D%7D/gists/2017-09-04-mediarecorder">demos</a> and the source <a href="https://github.com/zhirzh/zhirzh.github.io/blob/master/gists/2017-09-04-mediarecorder">code</a>.</p>
</article><footer class="related-posts"><nav><ul class="nav-list"><li class="related-posts-prev"><a href="/20171130-cra-apps-with-ssr">⟵ CRA apps with SSR</a></li><li class="related-posts-next"><a href="/20170730-correct-blur-with-de-gamma/">Correct blur with de-gamma ⟶</a></li></ul></nav></footer><footer class="social-links"><nav><ul class="nav-list"><li><a target="_blank" href="https://github.com/zhirzh">github</a></li><div class="dot">•</div><li><a target="_blank" href="https://medium.com/@zhirzh">medium</a></li><div class="dot">•</div><li><a target="_blank" href="https://twitter.com/zhirzh">twitter</a></li><div class="dot">•</div><li><a target="_blank" href="https://www.linkedin.com/in/shirsh-zibbu">linkedin</a></li><div class="dot">•</div><li><a target="_blank" href="https://stackoverflow.com/users/1343488/zhirzh">stackoverflow</a></li></ul></nav></footer></body></html>